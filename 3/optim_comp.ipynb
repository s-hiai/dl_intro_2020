{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 最適化手法の比較\n",
    "SGDとAdamを比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, init_value1, init_value2):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.w_1 = nn.Parameter(torch.tensor([init_value1]))\n",
    "        self.w_2 = nn.Parameter(torch.tensor([init_value2]))\n",
    "    \n",
    "    def forward_loss(self):\n",
    "        loss = (1/20) * self.w_1 ** 2 + self.w_2 ** 2 # (w_1, w_2) = (0, 0) が最適解\n",
    "        return loss\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期重み (SGDとAdamを比較するために初期重みを定めておく)\n",
    "init_val1 = random.random()\n",
    "init_val2 = random.random()\n",
    "\n",
    "# モデルのインスタンス (比較のために両方init_val1とinit_val2を初期重みにする)\n",
    "model_sgd = MyModel(init_val1, init_val2) # SGD用\n",
    "model_adam = MyModel(init_val1, init_val2) # Adam用"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SGD or Adamによる最適化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "op_sgd = optim.SGD(model_sgd.parameters(), lr=0.01) # lr:learning rate (学習率)\n",
    "op_adam = optim.Adam(model_adam.parameters(), lr=0.01) # lr:learning rate (学習率)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss_sgd:0.0003822590515483171, loss_adam:0.0003822590515483171\n",
      "sgd w1:0.08444901555776596, w2:0.005067271180450916\n",
      "adam w1:0.08444901555776596, w2:0.005067271180450916\n",
      "----------\n",
      "epoch: 1, loss_sgd:0.00038052938180044293, loss_adam:0.00030146457720547915\n",
      "sgd w1:0.08436456322669983, w2:0.0049659255892038345\n",
      "adam w1:0.07444902509450912, w2:-0.004932718351483345\n",
      "----------\n",
      "epoch: 2, loss_sgd:0.0003788414760492742, loss_adam:0.00022864290804136544\n",
      "sgd w1:0.08428020030260086, w2:0.004866607021540403\n",
      "adam w1:0.06450152397155762, w2:-0.004540988709777594\n",
      "----------\n",
      "epoch: 3, loss_sgd:0.00037719361716881394, loss_adam:0.0001500424405094236\n",
      "sgd w1:0.08419591933488846, w2:0.004769274964928627\n",
      "adam w1:0.05465327575802803, w2:-0.0008327120449393988\n",
      "----------\n",
      "epoch: 4, loss_sgd:0.0003755843499675393, loss_adam:0.0001087170749087818\n",
      "sgd w1:0.08411172032356262, w2:0.004673889372497797\n",
      "adam w1:0.044962070882320404, w2:0.0027636343147605658\n",
      "----------\n",
      "epoch: 5, loss_sgd:0.00037401216104626656, loss_adam:7.863571954658255e-05\n",
      "sgd w1:0.08402761071920395, w2:0.004580411594361067\n",
      "adam w1:0.035498443990945816, w2:0.003953320439904928\n",
      "----------\n",
      "epoch: 6, loss_sgd:0.00037247565342113376, loss_adam:4.2348867282271385e-05\n",
      "sgd w1:0.08394358307123184, w2:0.004488803446292877\n",
      "adam w1:0.026346910744905472, w2:0.0027642142958939075\n",
      "----------\n",
      "epoch: 7, loss_sgd:0.0003709733719006181, loss_adam:1.5641930076526478e-05\n",
      "sgd w1:0.0838596373796463, w2:0.004399027209728956\n",
      "adam w1:0.017606083303689957, w2:0.0003784468863159418\n",
      "----------\n",
      "epoch: 8, loss_sgd:0.00036950421053916216, loss_adam:8.050508768064901e-06\n",
      "sgd w1:0.08377578109502792, w2:0.004311046563088894\n",
      "adam w1:0.009386865422129631, w2:-0.001909147948026657\n",
      "----------\n",
      "epoch: 9, loss_sgd:0.0003680667432490736, loss_adam:9.137838787864894e-06\n",
      "sgd w1:0.08369200676679611, w2:0.0042248256504535675\n",
      "adam w1:0.0018078945577144623, w2:-0.002995732706040144\n",
      "----------\n",
      "epoch: 10, loss_sgd:0.0003666598640847951, loss_adam:7.856872798583936e-06\n",
      "sgd w1:0.08360831439495087, w2:0.004140329081565142\n",
      "adam w1:-0.005012203473597765, w2:-0.0025691951159387827\n",
      "----------\n",
      "epoch: 11, loss_sgd:0.00036528229247778654, loss_adam:7.157573236327153e-06\n",
      "sgd w1:0.08352470397949219, w2:0.004057522397488356\n",
      "adam w1:-0.01096519734710455, w2:-0.0010704182786867023\n",
      "----------\n",
      "epoch: 12, loss_sgd:0.0003639330971054733, loss_adam:1.3287566616781987e-05\n",
      "sgd w1:0.08344118297100067, w2:0.003976372070610523\n",
      "adam w1:-0.015964506193995476, w2:0.0007377633592113853\n",
      "----------\n",
      "epoch: 13, loss_sgd:0.00036261105560697615, loss_adam:2.4081540686893277e-05\n",
      "sgd w1:0.08335774391889572, w2:0.0038968445733189583\n",
      "adam w1:-0.019954677671194077, w2:0.0020425678230822086\n",
      "----------\n",
      "epoch: 14, loss_sgd:0.00036131523665972054, loss_adam:3.1653791666030884e-05\n",
      "sgd w1:0.08327438682317734, w2:0.0038189077749848366\n",
      "adam w1:-0.022916683927178383, w2:0.002322728745639324\n",
      "----------\n",
      "epoch: 15, loss_sgd:0.00036004459252581, loss_adam:3.343860953464173e-05\n",
      "sgd w1:0.08319111168384552, w2:0.003742529544979334\n",
      "adam w1:-0.024867968633770943, w2:0.0015867629554122686\n",
      "----------\n",
      "epoch: 16, loss_sgd:0.0003587981918826699, loss_adam:3.349715916556306e-05\n",
      "sgd w1:0.08310791850090027, w2:0.003667678916826844\n",
      "adam w1:-0.025858040899038315, w2:0.00025542674120515585\n",
      "----------\n",
      "epoch: 17, loss_sgd:0.0003575751034077257, loss_adam:3.482569445623085e-05\n",
      "sgd w1:0.08302480727434158, w2:0.003594325389713049\n",
      "adam w1:-0.02596149779856205, w2:-0.0010610013268887997\n",
      "----------\n",
      "epoch: 18, loss_sgd:0.0003563745704013854, loss_adam:3.516050855978392e-05\n",
      "sgd w1:0.08294178545475006, w2:0.0035224389284849167\n",
      "adam w1:-0.02527054026722908, w2:-0.0017973583890125155\n",
      "----------\n",
      "epoch: 19, loss_sgd:0.0003551956615410745, loss_adam:3.1392090022563934e-05\n",
      "sgd w1:0.0828588455915451, w2:0.003451990196481347\n",
      "adam w1:-0.023888392373919487, w2:-0.0016909537371248007\n",
      "----------\n",
      "epoch: 20, loss_sgd:0.00035403756191954017, loss_adam:2.4795392164378427e-05\n",
      "sgd w1:0.08277598768472672, w2:0.003382950322702527\n",
      "adam w1:-0.021924257278442383, w2:-0.0008727771928533912\n",
      "----------\n",
      "epoch: 21, loss_sgd:0.0003528995148371905, loss_adam:1.9052917195949703e-05\n",
      "sgd w1:0.08269321173429489, w2:0.003315291367471218\n",
      "adam w1:-0.019489796832203865, w2:0.00024557486176490784\n",
      "----------\n",
      "epoch: 22, loss_sgd:0.0003517807926982641, loss_adam:1.5276300473487936e-05\n",
      "sgd w1:0.08261051774024963, w2:0.0032489856239408255\n",
      "adam w1:-0.016696790233254433, w2:0.0011563561856746674\n",
      "----------\n",
      "epoch: 23, loss_sgd:0.00035068063880316913, loss_adam:1.149816580436891e-05\n",
      "sgd w1:0.08252790570259094, w2:0.0031840058509260416\n",
      "adam w1:-0.013655529357492924, w2:0.0014746157685294747\n",
      "----------\n",
      "epoch: 24, loss_sgd:0.00034959844197146595, loss_adam:6.723116257489892e-06\n",
      "sgd w1:0.08244537562131882, w2:0.0031203257385641336\n",
      "adam w1:-0.010473533533513546, w2:0.0011128210462629795\n",
      "----------\n",
      "epoch: 25, loss_sgd:0.0003485334455035627, loss_adam:2.7157429940416478e-06\n",
      "sgd w1:0.08236292749643326, w2:0.0030579192098230124\n",
      "adam w1:-0.007254257332533598, w2:0.0002907413290813565\n",
      "----------\n",
      "epoch: 26, loss_sgd:0.0003474850964266807, loss_adam:1.1850811461044941e-06\n",
      "sgd w1:0.08228056132793427, w2:0.0029967608861625195\n",
      "adam w1:-0.004095585085451603, w2:-0.0005885491846129298\n",
      "----------\n",
      "epoch: 27, loss_sgd:0.00034645278356038034, loss_adam:1.3167689303372754e-06\n",
      "sgd w1:0.08219827711582184, w2:0.0029368256218731403\n",
      "adam w1:-0.0010880394838750362, w2:-0.0011214176192879677\n",
      "----------\n",
      "epoch: 28, loss_sgd:0.000345435953931883, loss_adam:1.3336701840671594e-06\n",
      "sgd w1:0.08211608231067657, w2:0.002878089202567935\n",
      "adam w1:0.0016872521955519915, w2:-0.0010914802551269531\n",
      "----------\n",
      "epoch: 29, loss_sgd:0.000344433996360749, loss_adam:1.1797393426604685e-06\n",
      "sgd w1:0.08203396946191788, w2:0.0028205274138599634\n",
      "adam w1:0.004160659853368998, w2:-0.0005605219048447907\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    loss_sgd = model_sgd.forward_loss()\n",
    "    loss_adam = model_adam.forward_loss()\n",
    "    print(\"epoch: {}, loss_sgd:{}, loss_adam:{}\".format(epoch, float(loss_sgd.data), float(loss_adam.data)))\n",
    "    print(\"sgd w1:{}, w2:{}\".format(float(model_sgd.w_1), float(model_sgd.w_2)))\n",
    "    print(\"adam w1:{}, w2:{}\".format(float(model_adam.w_1), float(model_adam.w_2)))\n",
    "    print(\"-\"*10)\n",
    "\n",
    "    # 逆伝搬 (勾配の設定)\n",
    "    loss_sgd.backward()\n",
    "    loss_adam.backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    op_sgd.step()\n",
    "    op_adam.step()\n",
    "\n",
    "    # 勾配の消去\n",
    "    model_sgd.zero_grad()\n",
    "    model_adam.zero_grad()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
