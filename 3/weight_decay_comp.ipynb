{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Weight decay (L2正則化) ありなしの比較"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### モデルの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "import torch\n",
    "import torch.utils.data\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "class MyModel(nn.Module):\n",
    "    def __init__(self, init_value1, init_value2):\n",
    "        super(MyModel, self).__init__()\n",
    "        self.w_1 = nn.Parameter(torch.tensor([init_value1]))\n",
    "        self.w_2 = nn.Parameter(torch.tensor([init_value2]))\n",
    "    \n",
    "    def forward_loss(self):\n",
    "        loss = (1/20) * self.w_1 ** 2 + self.w_2 ** 2\n",
    "        return loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初期重み (Weight decayありなしを比較するために初期重みを定めておく)\n",
    "init_val1 = random.random()\n",
    "init_val2 = random.random()\n",
    "\n",
    "# モデルのインスタンス (比較のために両方init_val1とinit_val2を初期重みにする)\n",
    "model = MyModel(init_val1, init_val2)\n",
    "model_wd = MyModel(init_val1, init_val2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 最適化手法の定義\n",
    "weight decayあり・なし"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "op = optim.SGD(model.parameters(), lr=0.01) # lr:learning rate (学習率)\n",
    "op_wd = optim.SGD(model_wd.parameters(), lr=0.01, weight_decay=0.01) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0, loss:0.010829604230821133, loss_wd:0.009758861735463142\n",
      "sgd w1:0.465394526720047, w2:2.5314715458080173e-05\n",
      "sgd_wd w1:0.4417886435985565, w2:2.4006429157452658e-05\n",
      "----------\n",
      "epoch: 1, loss:0.01080795656889677, loss_wd:0.009737404063344002\n",
      "sgd w1:0.46492913365364075, w2:2.4808421585476026e-05\n",
      "sgd_wd w1:0.44130268692970276, w2:2.3523900381405838e-05\n",
      "----------\n",
      "epoch: 2, loss:0.01078635174781084, loss_wd:0.009715993888676167\n",
      "sgd w1:0.4644642174243927, w2:2.431225402688142e-05\n",
      "sgd_wd w1:0.440817266702652, w2:2.3051070456858724e-05\n",
      "----------\n",
      "epoch: 3, loss:0.010764788836240768, loss_wd:0.009694630280137062\n",
      "sgd w1:0.46399974822998047, w2:2.3826009055483155e-05\n",
      "sgd_wd w1:0.4403323531150818, w2:2.2587744751945138e-05\n",
      "----------\n",
      "epoch: 4, loss:0.010743271559476852, loss_wd:0.009673313237726688\n",
      "sgd w1:0.46353575587272644, w2:2.3349488401436247e-05\n",
      "sgd_wd w1:0.4398479759693146, w2:2.2133730453788303e-05\n",
      "----------\n",
      "epoch: 5, loss:0.01072179526090622, loss_wd:0.00965204369276762\n",
      "sgd w1:0.4630722105503082, w2:2.288249925186392e-05\n",
      "sgd_wd w1:0.43936413526535034, w2:2.1688842025469057e-05\n",
      "----------\n",
      "epoch: 6, loss:0.010700361803174019, loss_wd:0.009630819782614708\n",
      "sgd w1:0.4626091420650482, w2:2.2424848793889396e-05\n",
      "sgd_wd w1:0.4388808310031891, w2:2.1252895749057643e-05\n",
      "----------\n",
      "epoch: 7, loss:0.01067897118628025, loss_wd:0.009609643369913101\n",
      "sgd w1:0.462146520614624, w2:2.1976351490593515e-05\n",
      "sgd_wd w1:0.4383980631828308, w2:2.0825713363592513e-05\n",
      "----------\n",
      "epoch: 8, loss:0.010657623410224915, loss_wd:0.009588513523340225\n",
      "sgd w1:0.46168437600135803, w2:2.153682362404652e-05\n",
      "sgd_wd w1:0.4379158318042755, w2:2.040711660811212e-05\n",
      "----------\n",
      "epoch: 9, loss:0.010636317543685436, loss_wd:0.009567431174218655\n",
      "sgd w1:0.46122267842292786, w2:2.110608693328686e-05\n",
      "sgd_wd w1:0.4374341368675232, w2:1.9996932678623125e-05\n",
      "----------\n",
      "epoch: 10, loss:0.01061505638062954, loss_wd:0.00954639445990324\n",
      "sgd w1:0.4607614576816559, w2:2.0683964976342395e-05\n",
      "sgd_wd w1:0.43695294857025146, w2:1.9594994228100404e-05\n",
      "----------\n",
      "epoch: 11, loss:0.010593836195766926, loss_wd:0.009525403380393982\n",
      "sgd w1:0.4603006839752197, w2:2.0270284949219786e-05\n",
      "sgd_wd w1:0.4364722967147827, w2:1.9201135728508234e-05\n",
      "----------\n",
      "epoch: 12, loss:0.010572659783065319, loss_wd:0.009504458867013454\n",
      "sgd w1:0.4598403871059418, w2:1.9864879504893906e-05\n",
      "sgd_wd w1:0.43599218130111694, w2:1.8815193470800295e-05\n",
      "----------\n",
      "epoch: 13, loss:0.010551524348556995, loss_wd:0.009483561851084232\n",
      "sgd w1:0.45938053727149963, w2:1.946758129633963e-05\n",
      "sgd_wd w1:0.43551260232925415, w2:1.8437007383909076e-05\n",
      "----------\n",
      "epoch: 14, loss:0.010530431754887104, loss_wd:0.009462709538638592\n",
      "sgd w1:0.4589211642742157, w2:1.9078230252489448e-05\n",
      "sgd_wd w1:0.43503352999687195, w2:1.8066422853735276e-05\n",
      "----------\n",
      "epoch: 15, loss:0.010509382002055645, loss_wd:0.009441902860999107\n",
      "sgd w1:0.4584622383117676, w2:1.8696666302275844e-05\n",
      "sgd_wd w1:0.4345549941062927, w2:1.7703287085168995e-05\n",
      "----------\n",
      "epoch: 16, loss:0.010488374158740044, loss_wd:0.009421142749488354\n",
      "sgd w1:0.45800378918647766, w2:1.8322733012610115e-05\n",
      "sgd_wd w1:0.4340769946575165, w2:1.7347450921079144e-05\n",
      "----------\n",
      "epoch: 17, loss:0.010467407293617725, loss_wd:0.009400426410138607\n",
      "sgd w1:0.45754578709602356, w2:1.7956277588382363e-05\n",
      "sgd_wd w1:0.4335995018482208, w2:1.6998767023324035e-05\n",
      "----------\n",
      "epoch: 18, loss:0.01044648326933384, loss_wd:0.009379757568240166\n",
      "sgd w1:0.4570882320404053, w2:1.75971526914509e-05\n",
      "sgd_wd w1:0.43312254548072815, w2:1.665709169174079e-05\n",
      "----------\n",
      "epoch: 19, loss:0.010425600223243237, loss_wd:0.009359133429825306\n",
      "sgd w1:0.4566311538219452, w2:1.724520916468464e-05\n",
      "sgd_wd w1:0.43264612555503845, w2:1.632228486414533e-05\n",
      "----------\n",
      "epoch: 20, loss:0.010404760017991066, loss_wd:0.009338554926216602\n",
      "sgd w1:0.4561745226383209, w2:1.6900305126910098e-05\n",
      "sgd_wd w1:0.43217021226882935, w2:1.599420647835359e-05\n",
      "----------\n",
      "epoch: 21, loss:0.010383959859609604, loss_wd:0.009318022057414055\n",
      "sgd w1:0.45571833848953247, w2:1.6562298696953803e-05\n",
      "sgd_wd w1:0.4316948354244232, w2:1.5672723748139106e-05\n",
      "----------\n",
      "epoch: 22, loss:0.010363203473389149, loss_wd:0.009297532960772514\n",
      "sgd w1:0.4552626311779022, w2:1.623105345061049e-05\n",
      "sgd_wd w1:0.4312199652194977, w2:1.5357702068286017e-05\n",
      "----------\n",
      "epoch: 23, loss:0.010342487134039402, loss_wd:0.00927708949893713\n",
      "sgd w1:0.4548073709011078, w2:1.5906432963674888e-05\n",
      "sgd_wd w1:0.4307456314563751, w2:1.504901229054667e-05\n",
      "----------\n",
      "epoch: 24, loss:0.010321812704205513, loss_wd:0.009256691671907902\n",
      "sgd w1:0.45435255765914917, w2:1.5588304449920543e-05\n",
      "sgd_wd w1:0.43027180433273315, w2:1.474652708566282e-05\n",
      "----------\n",
      "epoch: 25, loss:0.010301179252564907, loss_wd:0.009236338548362255\n",
      "sgd w1:0.45389819145202637, w2:1.52765387610998e-05\n",
      "sgd_wd w1:0.42979851365089417, w2:1.445012185286032e-05\n",
      "----------\n",
      "epoch: 26, loss:0.010280586779117584, loss_wd:0.009216029196977615\n",
      "sgd w1:0.45344430208206177, w2:1.4971007658459712e-05\n",
      "sgd_wd w1:0.42932572960853577, w2:1.4159674719849136e-05\n",
      "----------\n",
      "epoch: 27, loss:0.010260036215186119, loss_wd:0.009195765480399132\n",
      "sgd w1:0.452990859746933, w2:1.4671587450720835e-05\n",
      "sgd_wd w1:0.42885348200798035, w2:1.3875065633328632e-05\n",
      "----------\n",
      "epoch: 28, loss:0.010239525698125362, loss_wd:0.009175545535981655\n",
      "sgd w1:0.45253786444664, w2:1.4378155356098432e-05\n",
      "sgd_wd w1:0.4283817410469055, w2:1.3596177268482279e-05\n",
      "----------\n",
      "epoch: 29, loss:0.010219057090580463, loss_wd:0.00915537029504776\n",
      "sgd w1:0.45208531618118286, w2:1.409059223078657e-05\n",
      "sgd_wd w1:0.4279105067253113, w2:1.3322894119482953e-05\n",
      "----------\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(30):\n",
    "    loss = model.forward_loss()\n",
    "    loss_wd = model_wd.forward_loss()\n",
    "    print(\"epoch: {}, loss:{}, loss_wd:{}\".format(epoch, float(loss.data), float(loss_wd.data)))\n",
    "    print(\"sgd w1:{}, w2:{}\".format(float(model.w_1), float(model.w_2)))\n",
    "    print(\"sgd_wd w1:{}, w2:{}\".format(float(model_wd.w_1), float(model_wd.w_2)))\n",
    "    print(\"-\"*10)\n",
    "\n",
    "    # 逆伝搬 (勾配の設定)\n",
    "    loss.backward()\n",
    "    loss_wd.backward()\n",
    "\n",
    "    # パラメータの更新\n",
    "    op.step()\n",
    "    op_wd.step()\n",
    "\n",
    "    # 勾配の消去\n",
    "    model.zero_grad()\n",
    "    model_wd.zero_grad()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
