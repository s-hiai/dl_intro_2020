{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 学習済みモデルの読み込みと評価データによる評価"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データ・モデルの読み込み（学習・訓練時と同様）\n",
    "\n",
    " - データは極性判定コーパスの一部を利用 <br />\n",
    "     - 学習・開発データとは別データ\n",
    " - モデルは多層パーセプトロン（MLP）を利用 <br />\n",
    "     - モデルのインスタンスを作って，そのモデルに学習済みパラメータを読み込んで設定する\n",
    " - 文章をBoWで表現し，MLPで分類\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import random\n",
    "\n",
    "from tqdm import tqdm\n",
    "import MeCab\n",
    "import torch\n",
    "from torch import optim\n",
    "\n",
    "from data import Sentence\n",
    "from data import DataSet\n",
    "from data import DataLoader\n",
    "from mlp import MultiLayer # 多層パーセプトロンを利用\n",
    "\n",
    "mecab_parser = MeCab.Tagger(\"-Owakati -d /usr/local/lib/mecab/dic/mecab-ipadic-neologd\")\n",
    "mecab_parser.parse(\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_document(path):\n",
    "    \"\"\"\n",
    "    データ読み込み用関数\n",
    "    Args:\n",
    "        path:対象ファイルのパス\n",
    "    Return:\n",
    "        tag_list (List[string])  :一行ごとのタグを要素に持つリスト\n",
    "        sentences_list (List[string]):一行ごとの文を要素に持つリスト\n",
    "    \"\"\"\n",
    "    with open(path) as f:\n",
    "        texts = f.readlines()\n",
    "\n",
    "    sentences_list,tag_list = [],[]\n",
    "    for row in texts:\n",
    "        sentence_list = []\n",
    "        tag,words = map(str,row.split(\"\\t\"))\n",
    "        tag_list.append(tag)\n",
    "        node = mecab_parser.parseToNode(words.replace('\\n',''))\n",
    "        while node:\n",
    "            analysis = node.feature.split(',')\n",
    "            if analysis[0] != 'BOS/EOS':\n",
    "                if analysis[0] == '名詞' and node.surface != '':\n",
    "                    sentence_list.append(node.surface)\n",
    "                elif analysis[6] != '':\n",
    "                    sentence_list.append(analysis[6])\n",
    "            node = node.next\n",
    "        sentences_list.append(sentence_list)\n",
    "    return tag_list, sentences_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータのパス\n",
    "test_path = \"test_data.txt\"\n",
    "\n",
    "# 文書の読み込み\n",
    "test_labels, test = load_document(test_path)\n",
    "test_data = DataSet(test, vocab=vocab, label_dict=label_to_id_dict)\n",
    "test_data_size = len(test_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練時の語彙リストの読み込み (BoW作成のため)\n",
    "vocab = [l.strip() for l in open(\"vocab.txt\")]\n",
    "# ラベル辞書の読み込み（学習時に出力層のどの次元がどのクラスと対応していたか判別するため）\n",
    "label_to_id_dict = {}\n",
    "id_to_label_dict = {}\n",
    "for l in open(\"label_dict.tsv\"):\n",
    "    label_name, label_id = l.strip().split(\"\\t\")\n",
    "    label_to_id_dict[label_name] = int(label_id)\n",
    "    id_to_label_dict[int(label_id)] = label_name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 学習済みモデルの読み込み"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# モデルのインスタンスを作成（初期化）\n",
    "multi_layer_model = MultiLayer(len(vocab), len(label_to_id_dict))\n",
    "# パラメータをモデルインスタンスにロード\n",
    "multi_layer_model.load_state_dict(torch.load(\"output_models/best_model\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 評価データでの評価"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# testデータでの評価\n",
    "multi_layer_model.eval()\n",
    "test_data_loader = DataLoader(test_data, batch_size=10, shuffle=False)\n",
    "predicted_label_id_list = multi_layer_model.test(test_data_loader) # モデルから予測結果のidが出力される\n",
    "\n",
    "predicted_label_list = [id_to_label_dict[idx.item()] for idx in predicted_label_id_list] # idをラベル名に直す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "          +1     0.6827    0.7100    0.6961       100\n",
      "          -1     0.6979    0.6700    0.6837       100\n",
      "\n",
      "    accuracy                         0.6900       200\n",
      "   macro avg     0.6903    0.6900    0.6899       200\n",
      "weighted avg     0.6903    0.6900    0.6899       200\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "report = str(classification_report(test_labels, predicted_label_list, digits=4))\n",
    "print(report)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
