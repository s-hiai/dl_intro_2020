{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LSTMによる分類\n",
    "torch.nn.Embeddingとtorch.nn.LSTMを利用 <br />\n",
    "<br />\n",
    "<img src=\"figures/LSTM.jpg\" width=\"320px\" align=\"left\"><br clear=\"all\" />\n",
    "<br />\n",
    "上記は1データ（1系列）を入力する場合のイメージ．<br />\n",
    "以下では，複数のデータをまとめて一つのミニバッチとして入力する場合の実装を示す． <br />"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### データの読み込みと整形\n",
    "単語分割 -> 各単語をidに変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "from data import Corpus # 自作クラス\n",
    "dataset = Corpus(\"text_data.txt\")\n",
    "vocab_size = len(dataset.word_to_id_dict) # 総語彙数 (入力サイズ)\n",
    "output_size = len(dataset.label_to_id_dict) # ラベル数 (出力サイズ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "系列長: 5 ['素晴らしい', '商品', 'だ', 'と', '思う'] [4, 5, 6, 7, 8]\n",
      "系列長: 8 ['値段', 'が', '安く', '、', '気兼ね', 'なく', '使い捨て', 'できる'] [9, 10, 11, 12, 13, 14, 15, 16]\n",
      "系列長: 4 ['いい', '音', 'が', 'する'] [17, 18, 10, 19]\n",
      "系列長: 5 ['変', 'な', 'におい', 'が', 'する'] [20, 21, 22, 10, 19]\n",
      "系列長: 6 ['初期', '不良', 'で', '使え', 'なかっ', 'た'] [23, 24, 25, 26, 27, 28]\n",
      "系列長: 5 ['保障', 'が', 'なく', 'て', '怖い'] [29, 10, 14, 30, 31]\n"
     ]
    }
   ],
   "source": [
    "input_sentence_list = dataset.train_sentence_list\n",
    "for sent in input_sentence_list:\n",
    "    print(\"系列長:\", len(sent), sent.word_list, sent.word_id_list)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LMSTによるミニバッチ処理のための前処理\n",
    "\n",
    "系列長が長い順にソート"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy\n",
    "\n",
    "input_sentence_idx_list = [i for i in range(len(input_sentence_list))]\n",
    "input_sentence_idx_list.sort(key=lambda x: len(input_sentence_list[x]), reverse=True)\n",
    "sorted_input_sentence_list = list(numpy.array(input_sentence_list)[input_sentence_idx_list])\n",
    "length_list = [len(sentence) for sentence in sorted_input_sentence_list]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "ミニバッチ処理ではすべてのデータを同様に処理したいので，<br />\n",
    "系列長を合わせるためにゼロ埋め（パディング）する．<br />\n",
    "（パディング用のidを決めておけば0でなくても良い．）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 9, 10, 11, 12, 13, 14, 15, 16],\n",
       "        [23, 24, 25, 26, 27, 28,  0,  0],\n",
       "        [ 4,  5,  6,  7,  8,  0,  0,  0],\n",
       "        [20, 21, 22, 10, 19,  0,  0,  0],\n",
       "        [29, 10, 14, 30, 31,  0,  0,  0],\n",
       "        [17, 18, 10, 19,  0,  0,  0,  0]])"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "pad_sentence_list = nn.utils.rnn.pad_sequence([torch.tensor(sentence.word_id_list) for sentence in sorted_input_sentence_list], batch_first=True)\n",
    "pad_sentence_list"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 単語のEmbeddingへの変換とLSTMの入出力\n",
    "\n",
    "<br />\n",
    "<img src=\"figures/batch.jpg\" width=\"320px\" align=\"left\"><br clear=\"all\" />\n",
    "<br />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding層の定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "embedding_size = 5\n",
    "embeddings = nn.Embedding(vocab_size, embedding_size, padding_idx=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Embedding層への入力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence_embeds = embeddings(pad_sentence_list) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### padding情報を含んだデータ構造への変換"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "PackedSequence(data=tensor([[-0.4551,  0.0084,  0.4175,  1.9827,  0.6220],\n",
      "        [-0.5047,  0.7191,  0.2714, -0.3522, -0.9492],\n",
      "        [-0.0289,  0.6725,  0.9195, -0.6540, -0.1145],\n",
      "        [-0.8802, -0.4558,  0.9525,  0.9191, -0.5917],\n",
      "        [-2.4431,  0.0489,  0.0073,  1.3766,  1.3467],\n",
      "        [ 0.6157, -0.1077,  1.0916,  0.2613,  0.5627],\n",
      "        [ 0.4615, -0.6179, -1.1043,  0.0164,  2.4451],\n",
      "        [-0.5915,  0.5454,  0.8148, -0.8063, -0.0991],\n",
      "        [ 1.4891,  0.8939, -0.1632,  0.5619,  0.8970],\n",
      "        [ 1.2558, -0.4836,  1.3804, -0.1532,  1.5678],\n",
      "        [ 0.4615, -0.6179, -1.1043,  0.0164,  2.4451],\n",
      "        [ 2.5973,  1.1144,  0.2929,  1.9031, -0.8557],\n",
      "        [ 2.2469, -2.1323,  1.2446, -0.1291, -1.2582],\n",
      "        [-2.1239,  0.3752, -1.2123,  0.8049,  0.4078],\n",
      "        [ 0.9385,  0.4654,  1.2850, -0.4962, -0.4349],\n",
      "        [ 0.4180, -0.1056,  0.8720, -0.1217, -1.0491],\n",
      "        [-0.6997,  1.0598,  0.2474,  1.6757,  0.6807],\n",
      "        [ 0.4615, -0.6179, -1.1043,  0.0164,  2.4451],\n",
      "        [ 0.8873,  0.5645, -0.7094, -0.0779, -0.1466],\n",
      "        [-0.4899,  0.1197, -0.1566, -0.3429, -0.5651],\n",
      "        [-0.9592, -0.0324,  0.7044, -1.2599, -0.6086],\n",
      "        [ 0.4615, -0.6179, -1.1043,  0.0164,  2.4451],\n",
      "        [ 1.5944, -0.5475, -0.6332, -0.2439,  0.2302],\n",
      "        [ 0.8783, -1.2765,  0.3341,  0.3787, -0.0196],\n",
      "        [ 1.5250, -0.3560,  0.5146, -0.3271,  1.3744],\n",
      "        [-0.1215, -0.0071,  0.2758,  1.8833,  0.6387],\n",
      "        [ 1.4821, -0.7772, -0.0954, -0.3479, -0.4412],\n",
      "        [ 0.8783, -1.2765,  0.3341,  0.3787, -0.0196],\n",
      "        [-0.9293, -0.4857, -2.3015,  0.0539,  2.1252],\n",
      "        [-0.6997,  1.0598,  0.2474,  1.6757,  0.6807],\n",
      "        [ 1.4709,  2.0660, -0.0813,  1.6050,  1.7644],\n",
      "        [ 0.6472,  0.1029, -0.5300, -0.9250, -0.7447],\n",
      "        [ 1.0387,  0.4126,  0.8858,  1.8162,  0.4338]],\n",
      "       grad_fn=<PackPaddedSequenceBackward>), batch_sizes=tensor([6, 6, 6, 6, 5, 2, 1, 1]), sorted_indices=None, unsorted_indices=None)\n"
     ]
    }
   ],
   "source": [
    "sentence_embeds = nn.utils.rnn.pack_padded_sequence(sentence_embeds, length_list, batch_first=True) # パディングの情報を含んだLSTMへの入力形式\n",
    "print(sentence_embeds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMの定義"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_input_size = embedding_size\n",
    "rnn_hidden_size = 3\n",
    "lstm = nn.LSTM(\n",
    "    rnn_input_size, \n",
    "    rnn_hidden_size, \n",
    "    num_layers=1, # LSTM_1(LSTM_2((...のようにLSTM を多段にすることができる  今回は一層のみ\n",
    "    batch_first=True # 入力の形式を指定 (batch_size, 系列長, 分散表現の次元) のようにbatch_sizeが最初に来るよう入力\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LSTMへの入力"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_outputs, hidden_cell_tensors = lstm(sentence_embeds) # lstmの計算 各段階での出力 (lstm_outputs) とパディング部分を除いた最終的な出力 (hidden_cell_tensors)が返ってくる"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "lstm_outputs：各段階での出力 <br />\n",
    "<br />\n",
    "<img src=\"figures/lstm_outputs.jpg\" width=\"320px\" align=\"left\"><br clear=\"all\" />\n",
    "<br />\n",
    "hidden_cell_tensors[0]：最終状態の出力 <br />\n",
    "hidden_cell_tensors[1]：最終状態のメモリセル <br />\n",
    "<br />\n",
    "<img src=\"figures/hidden_cell.jpg\" width=\"320px\" align=\"left\"><br clear=\"all\" />\n",
    "<br />"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nn.lstmの各段階での出力の整形とパディング部分をゼロベクトルへの置き換え\n",
    "lstm_outputs, output_lengths = nn.utils.rnn.pad_packed_sequence(lstm_outputs, batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.2708,  0.1403,  0.3248],\n",
       "         [ 0.2898,  0.1016,  0.0380],\n",
       "         [-0.4225,  0.0207, -0.0419],\n",
       "         [-0.3185,  0.0352, -0.0196],\n",
       "         [-0.0980,  0.0291, -0.0991],\n",
       "         [ 0.0850,  0.1830,  0.2034],\n",
       "         [-0.1953,  0.0536,  0.0346],\n",
       "         [ 0.1697,  0.0711,  0.2374]],\n",
       "\n",
       "        [[ 0.0183,  0.0691,  0.1739],\n",
       "         [ 0.0540,  0.0856,  0.2132],\n",
       "         [ 0.1959,  0.2909,  0.2681],\n",
       "         [ 0.0793,  0.1587,  0.2252],\n",
       "         [ 0.3506,  0.2208,  0.4044],\n",
       "         [ 0.3659, -0.1445,  0.1934],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.0549,  0.0474,  0.1131],\n",
       "         [ 0.1416,  0.0043,  0.0934],\n",
       "         [ 0.0541,  0.0242,  0.1540],\n",
       "         [ 0.0380,  0.0543,  0.2076],\n",
       "         [-0.3362,  0.0312,  0.0168],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1773,  0.0777,  0.3446],\n",
       "         [ 0.2402,  0.0382,  0.1406],\n",
       "         [ 0.0964,  0.0434,  0.2419],\n",
       "         [ 0.2003,  0.0862,  0.0635],\n",
       "         [-0.0696,  0.0558,  0.0663],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1077,  0.2539,  0.2719],\n",
       "         [ 0.2133,  0.1242, -0.0200],\n",
       "         [ 0.2714,  0.2248,  0.3121],\n",
       "         [-0.1558,  0.0456,  0.0326],\n",
       "         [-0.0951,  0.1760, -0.0564],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]],\n",
       "\n",
       "        [[ 0.1647,  0.0401,  0.1152],\n",
       "         [-0.0720, -0.0507,  0.1423],\n",
       "         [ 0.0710,  0.0544,  0.1063],\n",
       "         [-0.1407,  0.0464,  0.0804],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000],\n",
       "         [ 0.0000,  0.0000,  0.0000]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lstm_outputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.1697,  0.0711,  0.2374],\n",
       "          [ 0.3659, -0.1445,  0.1934],\n",
       "          [-0.3362,  0.0312,  0.0168],\n",
       "          [-0.0696,  0.0558,  0.0663],\n",
       "          [-0.0951,  0.1760, -0.0564],\n",
       "          [-0.1407,  0.0464,  0.0804]]], grad_fn=<StackBackward>),\n",
       " tensor([[[ 0.2526,  0.1558,  0.7618],\n",
       "          [ 0.7865, -0.2674,  1.4051],\n",
       "          [-0.5172,  0.1364,  0.0590],\n",
       "          [-0.0972,  0.1907,  0.1366],\n",
       "          [-0.1388,  0.5359, -0.1011],\n",
       "          [-0.1990,  0.1589,  0.1732]]], grad_fn=<StackBackward>))"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hidden_cell_tensors"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### BiLSTMの利用\n",
    "モデルの定義<br />\n",
    "<b>bidirectional=True</b> の追加"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "bilstm = nn.LSTM(\n",
    "    rnn_input_size, \n",
    "    rnn_hidden_size, \n",
    "    num_layers=1, # LSTM_1(LSTM_2((...のようにLSTM を多段にすることができる  今回は一層のみ\n",
    "    batch_first=True, # 入力の形式を指定 (batch_size, 系列長, 分散表現の次元) のようにbatch_sizeが最初に来るよう入力\n",
    "    bidirectional=True # 双方向LSTMに\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm_outputs, hidden_cell_tensors = bilstm(sentence_embeds) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 5.0541e-02, -2.4209e-01, -9.3454e-02,  3.7103e-01, -9.2738e-03,\n",
       "           6.6723e-02],\n",
       "         [ 5.0225e-03, -6.2451e-01, -1.8603e-01,  3.3411e-01, -6.4509e-03,\n",
       "           1.6077e-01],\n",
       "         [ 1.8521e-01, -1.3036e-01, -6.3688e-01,  2.1698e-01,  2.3648e-01,\n",
       "           6.4992e-02],\n",
       "         [ 8.7559e-02,  3.2377e-02, -4.4821e-01,  2.1770e-01,  4.9263e-02,\n",
       "           5.7946e-02],\n",
       "         [ 1.5802e-01,  1.2415e-01, -5.7881e-01,  1.6962e-01,  1.2508e-01,\n",
       "           4.1428e-02],\n",
       "         [ 3.1383e-02, -4.1777e-02, -3.1888e-01,  2.4501e-01,  3.7735e-02,\n",
       "           4.1011e-02],\n",
       "         [ 1.4887e-04,  8.7179e-02, -5.4264e-01,  8.5091e-02,  5.9805e-02,\n",
       "           2.2037e-02],\n",
       "         [ 1.6317e-01,  2.7392e-02, -4.9134e-01,  4.5514e-02,  1.9806e-01,\n",
       "           6.4654e-02]],\n",
       "\n",
       "        [[-1.5590e-01,  2.9880e-02,  3.7991e-02,  2.0814e-01,  1.3574e-02,\n",
       "          -4.2747e-02],\n",
       "         [-1.8182e-01,  4.4231e-02,  1.7942e-02,  2.1107e-01, -1.6132e-02,\n",
       "          -2.3647e-02],\n",
       "         [-2.1243e-01, -4.7810e-02, -3.0109e-02,  4.9833e-01, -7.8530e-02,\n",
       "           7.7021e-02],\n",
       "         [-2.8721e-01, -5.3418e-02, -1.6028e-01,  1.7924e-01, -2.8266e-02,\n",
       "           3.2953e-02],\n",
       "         [-5.7195e-02, -2.9858e-01, -1.7865e-01,  1.4224e-01,  3.0220e-02,\n",
       "           5.1738e-02],\n",
       "         [ 6.1911e-02, -2.6946e-01, -3.7185e-01,  3.9562e-02,  1.0282e-01,\n",
       "           1.4512e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00]],\n",
       "\n",
       "        [[ 1.9613e-02,  8.5663e-02, -5.5493e-02,  8.5226e-02,  9.4887e-02,\n",
       "          -4.2997e-02],\n",
       "         [ 1.9529e-01,  1.1900e-01, -2.3162e-01,  7.0888e-02,  1.1910e-01,\n",
       "           2.6795e-02],\n",
       "         [ 3.5866e-01,  1.5637e-01, -3.6216e-01,  1.4785e-02,  1.1978e-01,\n",
       "          -2.1460e-02],\n",
       "         [ 1.3531e-01,  6.3490e-02, -1.9337e-01, -2.0055e-02, -4.5384e-02,\n",
       "           9.5251e-03],\n",
       "         [ 2.4405e-01,  2.1862e-01, -3.8975e-01,  4.1208e-02,  7.7228e-03,\n",
       "           9.4708e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00]],\n",
       "\n",
       "        [[ 5.4249e-02, -1.4939e-01, -2.5126e-02,  2.1403e-01,  8.5014e-03,\n",
       "           2.5466e-02],\n",
       "         [ 1.3155e-01, -1.4164e-01, -4.4248e-01,  1.0179e-01,  1.9616e-01,\n",
       "           3.1847e-02],\n",
       "         [ 2.3532e-01,  8.4269e-02, -4.3213e-01,  1.0034e-01,  4.0461e-02,\n",
       "           4.6692e-02],\n",
       "         [ 3.4854e-02, -2.8690e-01, -2.0676e-01,  1.4141e-01, -2.0042e-01,\n",
       "           1.2073e-01],\n",
       "         [ 1.3338e-01, -3.7028e-01, -4.3554e-01,  5.4934e-02, -7.6005e-02,\n",
       "           5.7701e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00]],\n",
       "\n",
       "        [[-6.0752e-02, -1.8531e-01, -4.6461e-02,  4.9133e-01, -1.7553e-01,\n",
       "           3.5688e-02],\n",
       "         [-6.9707e-03, -6.0298e-01, -1.8756e-01,  3.6398e-01, -1.5842e-01,\n",
       "           1.1876e-01],\n",
       "         [-1.0640e-01, -4.5077e-01, -2.5191e-01,  3.2263e-01, -3.8475e-03,\n",
       "           7.9987e-02],\n",
       "         [ 8.3824e-02, -3.6255e-01, -4.2175e-01,  2.0416e-01, -1.0975e-01,\n",
       "           1.8294e-01],\n",
       "         [-3.2245e-02, -5.9842e-01, -8.6510e-02,  2.6550e-01, -8.2429e-02,\n",
       "           9.6631e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00]],\n",
       "\n",
       "        [[ 1.4676e-01, -5.1016e-02, -2.7887e-01,  1.4048e-01,  1.8947e-01,\n",
       "           7.1308e-02],\n",
       "         [ 4.5340e-01,  1.3407e-01, -3.6914e-01,  1.0069e-01,  6.0508e-02,\n",
       "           2.5715e-01],\n",
       "         [ 4.9645e-02, -2.9458e-01, -1.8825e-01,  1.4141e-01, -2.0042e-01,\n",
       "           1.2073e-01],\n",
       "         [ 1.4282e-01, -3.8061e-01, -4.2010e-01,  5.4934e-02, -7.6005e-02,\n",
       "           5.7701e-02],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00],\n",
       "         [ 0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,  0.0000e+00,\n",
       "           0.0000e+00]]], grad_fn=<TransposeBackward0>)"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# nn.lstmの各段階での出力の整形とパディング部分をゼロベクトルへの置き換え\n",
    "lstm_outputs, output_lengths = nn.utils.rnn.pad_packed_sequence(lstm_outputs, batch_first=True)\n",
    "\n",
    "lstm_outputs # 各段階での出力 双方向の各段階での出力を連結 (3 * 2次元)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[ 0.1632,  0.0274, -0.4913],\n",
      "        [ 0.0619, -0.2695, -0.3718],\n",
      "        [ 0.2441,  0.2186, -0.3898],\n",
      "        [ 0.1334, -0.3703, -0.4355],\n",
      "        [-0.0322, -0.5984, -0.0865],\n",
      "        [ 0.1428, -0.3806, -0.4201]], grad_fn=<SelectBackward>)\n",
      "tensor([[ 0.3710, -0.0093,  0.0667],\n",
      "        [ 0.2081,  0.0136, -0.0427],\n",
      "        [ 0.0852,  0.0949, -0.0430],\n",
      "        [ 0.2140,  0.0085,  0.0255],\n",
      "        [ 0.4913, -0.1755,  0.0357],\n",
      "        [ 0.1405,  0.1895,  0.0713]], grad_fn=<SelectBackward>)\n",
      "tensor([[ 0.1963,  0.0391, -1.7540],\n",
      "        [ 0.0689, -0.3835, -0.6914],\n",
      "        [ 0.4870,  0.3829, -0.8055],\n",
      "        [ 0.2332, -0.5205, -1.5063],\n",
      "        [-0.1272, -0.8627, -0.9132],\n",
      "        [ 0.2494, -0.5367, -1.3334]], grad_fn=<SelectBackward>)\n",
      "tensor([[ 0.4780, -0.0240,  0.1452],\n",
      "        [ 0.4334,  0.0387, -0.1679],\n",
      "        [ 0.1899,  0.1902, -0.1436],\n",
      "        [ 0.2821,  0.0212,  0.1216],\n",
      "        [ 0.6161, -0.9453,  0.0942],\n",
      "        [ 0.2407,  0.3193,  0.1846]], grad_fn=<SelectBackward>)\n"
     ]
    }
   ],
   "source": [
    "# hidden_cell_tensors: 最終的な出力とメモリセル\n",
    "print(hidden_cell_tensors[0][0]) # 順方向LSTMの出力\n",
    "print(hidden_cell_tensors[0][1]) # 逆方向LSTMの出力\n",
    "print(hidden_cell_tensors[1][0]) # 順方向LSTMのメモリセル\n",
    "print(hidden_cell_tensors[1][1]) # 逆方向LSTMのメモリセル"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
